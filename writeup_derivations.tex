\documentclass{article}
\usepackage{graphicx,fancyhdr,amsmath,amssymb,amsthm,subfig,url,hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{multicol}
\setlength\parindent{0pt}

\newtheorem{fact}{Fact}[section]
\newtheorem{rules}{Rule}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{remark}{Remark}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}[section]
%\newenvironment{proof}{{\bf Proof.  }}{\hfill$\Box$}
\newenvironment{proofof}[1]{\noindent {\em Proof of #1.  }}{\hfill$\Box$}
\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{claim}{Claim}
\newtheorem{conjecture}{Conjecture}

\def \imp {\rightarrow}
\def \qed {\hfill $\Box$}
\def \R {{\mathbb R}}
\def \sR {{\mathcal R}}
\def \eps {\varepsilon}
\def \N {{\mathbb N}}
\def \Z {{\mathbb Z}}
\newcommand{\ignore}[1]{}
\newcommand{\fignore}[1]{#1}
\def \poly { \text{\rm poly~} }
\def \polylog { \text{\rm polylog~} }
\def\th{{\text{\rm th}}}

\begin{document}

\section{Problem description}
Consider a duopoly with two stores, $A$ and $B$, selling the same item. Store $A$ sells the item for a price $p$ while store $B$ sells it for price $p^{+} = p+\epsilon$ for some $\epsilon > 0$. Store $B$ also gives a reward $R$ to a customer after making $k$ purchases at $B$. Our goal is to find the optimal $k$ for store $B$ to maximize its rate of revenue under certain assumptions on customer behavior. \\

We assume that there is some exogenous probability, $\lambda$, during each purchase that forces the customer to go to store $B$. Let $0 < \beta \leq 1$ denote the discounting factor of future money. (NOTE/QUESTION: in the previous write-up, $\beta$ was called the expiry factor - is this still the correct interpretaion? If so, it seems like $\beta$ should be close to zero but in the discounting interpretation $\beta$ should be close to one) For simplicity, we assume the customer has the following utility as a function of price paid: $u(p) = v > 0$ and $u(p^+) = 0$. \\

We model the customer's decision problem as a dynamic problem. We index the number of visits the customer makes at store $B$ by $i$, for $0 \leq i \leq k-1$, and we refer a customer to be in state $i$ after having made $i$ visits to $B$. At state $i$, the customer has two possibilities:
\begin{enumerate}
\item
With probability $\lambda$, the customer must visit $B$, and she is now in state $i+1$.
\item
With probability $1-\lambda$, the customer may purchase from $A$ for utility $v$ and remain in state $i$ or purchase from $B$ for no utility but move to state $i+1$.
\end{enumerate}

Let $V(i)$ denote the long term expected reward at state $i$. Then we may model the decision problem as the following dynamic program.
\begin{gather*}
V(i) = \lambda \beta V(i+1) + (1-\lambda)\max\{v+\beta V(i),\beta V(i+1) \} \mbox{ for } 0\leq i \leq k-1 \\
V(k) = R
\end{gather*}

We will show that the decision process exhibits a phase transition; that is prior to some state $i_0$, the customer will only visit $B$ if she must do so exogenously but after $i_0$, she always decides to go to $B$. \\

Finally, we assume the customer has a look-ahead factor $t$, which models how many purchases ahead the customer looks ahead when making her current decision. This value will affect the phase transition of the decision process. Consider a distribution $T$ describing the look-ahead factor for consumers. We will focus on threshold distributions; for example, with probability $p$ the look-ahead is $t_1$ and with probability $1-p$, the look-ahead is $t_0$.

\section{Solving the DP and the phase transition}

NEED TO: find conditions under which $V(i)$ is increasing in $i$ and provide proof (these will be different than in the original write-up). The following lemma would be written as a part of this lemma. \\

\begin{lemma} We may write the DP as
\begin{equation*}
V(i) = \max\left\{ \frac{\lambda \beta V(i+1)+(1-\lambda)v}{1-(1-\lambda)\beta}, \beta V(i+1) \right\}
\end{equation*}
\end{lemma}

\begin{proof}
We have the following:
\begin{align*}
V(i) &= \lambda \beta V(i+1) + (1-\lambda)\max\{v +\beta V(i), \beta V(i+1) \} \\
&= \max\{\lambda \beta V(i+1) + (1-\lambda)(v+\beta V(i)), \beta V(i+1) \}
\end{align*}

Assuming $V(i)$ is the left term in the above maximum, we may solve the equation for that term.
\begin{gather*}
V(i) = \lambda \beta V(i+1) + (1-\lambda)(v+\beta V(i)) \\
(1-(1-\lambda)\beta) V(i) = \lambda \beta V(i+1) + (1-\lambda)v \\
V(i) = \frac{\lambda \beta V(i+1) + (1-\lambda)v}{1-(1-\lambda)\beta}
\end{gather*}\end{proof}

\begin{theorem} A phase transition occurs after the consumer makes $i_0$ visits to firm $B$, which evaluates to:
\begin{align*}
i_0 &= k - \left\lfloor{\log_{\beta}\left(\frac{v}{R\beta(1-\beta)} \right)}\right\rfloor \\
&\equiv k-\Delta
\end{align*}
\end{theorem}

(Note: we may need conditions as we did before - thing to check)

\begin{proof}
First we solve for the condition on $V(i+1)$ for us to choose firm $B$ over $A$ willingly.
\begin{gather*}
\beta V(i+1) \geq \frac{\lambda \beta V(i+1) + (1-\lambda)v}{1-(1-\lambda)\beta} \\
\iff \beta V(i+1) \left(1-\frac{\lambda}{1-(1-\lambda)\beta} \right) \geq \left(\frac{1-\lambda}{1-(1-\lambda)\beta} \right) v \\
\iff \beta V(i+1) \left(\frac{1-(1-\lambda)\beta -\lambda}{1-(1-\lambda)\beta} \right) \geq \left(\frac{1-\lambda}{1-(1-\lambda)\beta} \right) v \\
\iff \beta V(i+1) \left(\frac{(1-\lambda)(1-\beta)}{1-(1-\lambda)\beta} \right) \geq \left(\frac{1-\lambda}{1-(1-\lambda)\beta} \right) v \\
\iff \beta V(i+1) \geq \frac{v}{1-\beta} \\
\iff V(i+1) \geq \frac{v}{\beta(1-\beta)}
\end{gather*}
Let $i_0$ be the minimum state $i$ such that the above holds, so in particular $V(i_0) < \frac{v}{\beta(1-\beta)}$ but $V(i_0+1) \geq \frac{v}{\beta(1-\beta)}$. We know because $V$ is increasing in $i$ (still need to prove), this point is indeed a phase transition: $V(i) \geq \frac{v}{\beta(1-\beta)}$ for all $i > i_0$, so after this point, the consumer always chooses firm $B$. We may compute $V(i_0)$ easily using this fact.
\begin{equation*}
V(i_0) = \beta V(i_0+1) = \cdots = \beta^{k-i_0}V(k) = \beta^{k-i_0}R
\end{equation*}
Thus, we have the following:
\begin{gather*}
\beta^{k-i_0} < \frac{v}{R\beta(1-\beta)} \leq \beta^{k-(i_0+1)} \\ 
\iff k-i_0 < \log_{\beta}\left(\frac{v}{R\beta(1-\beta)} \right) \leq k-(i_0+1) \\
\iff i_0 > k - \log_{\beta}\left(\frac{v}{R\beta(1-\beta)} \right) \\
\iff i_0 = k - \left\lfloor \log_{\beta}\left(\frac{v}{R\beta(1-\beta)} \right) \right\rfloor \equiv k-\Delta
\end{gather*}
\end{proof}

\section{Look-ahead, threshold distribution}
Now we assume the look-ahead factor of a customer is drawn from some distribution $t \sim T$. The phase transition of the customer's DP will now depend on $t$.
\begin{equation*}
  i_0(t)=\begin{cases}
    i_0, & \text{if $t \geq \Delta$}.\\
    k-t, & \text{otherwise}.
  \end{cases}
\end{equation*}
Assuming a customer look-ahead distribution and a fixed reward size, $R$, we want to choose a $k$ to maximize the revenue per reward cycle. That is we want to maximize the quantity given by revenue of $B$ during the $k$ visits over the total number of purchases (at both $A$ and $B$) to reach $k$ visits at $B$. For simplicity we assume $p^+ = 1$, so the revenue of $B$ per reward cycle is $k-R$. The expected total number of purchases per reward cycle is $\frac{i_0(t)}{\lambda}+(k-i_0(t))$, where the first term represents the expected number of visits needed to reach the phase transition with exogonous visits to $B$ and the second term is just the remaining visits to $B$ to receive the reward. \\

Note that we can think of the length of the reward cycle as a random variable: length of cycle = $\tau+k-i_0(t)$ where $\tau$ is a random variable representing the number of visits needed to hit the phase transition and $E(\tau) = \frac{i_0(t)}{\lambda}$. Ideally, we would like to maximize the following objective function over $k$: $E_{\tau,t}\left(\frac{k-R}{\tau+k-i_0(t)} \right)$. We have some expressions for this objective function (which I can write up later or in separate document), but for now we will focus on a simpler objective: $E_t\left(\frac{k-R}{E_{\tau}(\tau+k-i_0(t)}\right) = E_t\left(\frac{k-R}{i_0(t)/\lambda+k-i_0(t)} \right)$. We hope that this change still models reality well (maybe we can prove this for further justification?). \\

In this section, we focus on a very simple threshold distribution given by the following.
\begin{equation*}
  i_0(t)=\begin{cases}
    t_1\geq \Delta, & \text{wp } p,\\
    t_0 < \Delta, & \text{wp } 1-p.
  \end{cases}
\end{equation*}

\begin{lemma}
The objective function for the above look-ahead distribution is given by:
\begin{equation*}
f(k) = \frac{\lambda (k-R)p}{k-(1-\lambda)\Delta}+\frac{\lambda (k-R)(1-p)}{k-(1-\lambda)t_0}
\end{equation*}
\end{lemma}

\begin{proof}
\begin{align*}
E_t\left(\frac{k-R}{\frac{i_0(t)}{\lambda}+k-i_0(t)} \right) &= \frac{(k-R)p}{\frac{i_0}{\lambda}+k-i_0}+\frac{(k-R)(1-p)}{\frac{k-t_0}{\lambda}+k-(k-t-0)} \\
&= \frac{\lambda(k-R)p}{i_0+\lambda(k-i_0)}+\frac{\lambda(k-R)(1-p)}{k-t_0+t_0\lambda} \\
&= \frac{\lambda(k-R)p}{k-\Delta+\lambda(\Delta)}+\frac{\lambda(k-R)(1-p)}{k-t_0+t_0\lambda} \\
&= \frac{\lambda (k-R)p}{k-(1-\lambda)\Delta}+\frac{\lambda (k-R)(1-p)}{k-(1-\lambda)t_0} \equiv f(k)
\end{align*}
\end{proof}

We wish to maximize this objective function for $k>\Delta$ (otherwise $i_0$ would be negative). Next, we will characterize the conditions under which we can maximize the function and what the maxima are.

\begin{lemma}
If $(1-\lambda)t_0 \leq R \leq (1-\lambda)\Delta$, the above objective function has real-valued critical points.
\end{lemma}

\begin{proof}
First we differentiate $f(k)$.
\begin{align*}
\frac{df}{dk} &= \frac{\lambda(k-(1-\lambda)\Delta)-\lambda(k-R)p}{(k-(1-\lambda)\Delta)^2}+\frac{\lambda(1-p)(k-(1-\lambda)t_0)-\lambda(k-R)(1-p)}{(k-(1-\lambda)t_0)^2} \\
&= \frac{\lambda p(R-(1-\lambda)\Delta)}{(k-(1-\lambda)\Delta)^2} + \frac{\lambda(1-p)(R-(1-\lambda)t_0)}{(k-(1-\lambda)t_0)^2}
\end{align*}
Setting equal to zero and solving for $k$ we get the following. Let $c_1 = R-(1-\lambda)\Delta$ and $c_2 = R-(1-\lambda)t_0$.
\begin{gather*}
pc_1(k-(1-\lambda)t_0)^2 = -(1-p)c_2(k-(1-\lambda)R)^2 \\
\iff (pc_1)k^2-(2pc_1(1-\lambda))k+(pc_1(1-\lambda)^2t_0^2 = (-(1-p)c_2)k^2+(2(1-p)(1-\lambda)c_2\Delta)k-((1-p)c_2(1-\lambda)^2\Delta^2) \\
\iff (pc_1+(1-p)c_2)k^2-2(1-\lambda)(pc_1t_0+(1-p)c_2\Delta)k+(1-\lambda)^2(pc_1t_0^2+(1-p)c_2\Delta^2) = 0
\end{gather*}
For the above to have real-valued solutions, we need:
\begin{gather*}
4(1-\lambda)^2(pc_1t_0+(1-p)c_2\Delta)^2 - 4(pc_1+(1-p)c_2)(1-\lambda)^2(pc_1t_0^2+(1-p)c_2\Delta^2) \geq 0 \\
\iff p^2c_1^2t_0^2+(1-p)^2c_2^2\Delta^2+2p(1-p)c_1c_2t_0\Delta - p^2c_1^2t_0^2+(1-p)^2c_2^2\Delta^2+p(1-p)c_1c_2t_0^2+p(1-p)c_1c_2\Delta^2 \geq 0 \\
\iff p(1-p)c_1c_2(2t_0\Delta-\Delta^2-t_0^2) \geq 0 \\
\iff -p(1-p)c_1c_2(t_0-\Delta)^2 \geq 0 \\
\iff -p(1-p)c_1c_2 \geq 0 \\
\iff c_1c_2 \leq 0
\end{gather*}
The constraint that $c_1c_2 \leq 0$ means $(R-(1-\lambda)\Delta)(R-(1-\lambda)t_0) \leq 0$. Because $R \geq 0$, $(1-\lambda) \geq 0$ and $t_0 < \Delta$, we also have that $(R-(1-\lambda)\Delta) < (R-(1-\lambda)t_0)$. So we must have:
\begin{gather*}
(R-(1-\lambda)\Delta) \leq 0 \leq (R-(1-\lambda)t_0) \\
\iff (1-\lambda)t_0 \leq R \leq (1-\lambda)\Delta
\end{gather*}
\end{proof}

Note that $\Delta$ depends on $R$, so the above inequality is more complicated than as written. TODO - see if we can get a nice inequality for $R$ not in terms of $\Delta$. (Can also add a sample plot here). \\

Now need to check that this is actually a maximum.
\end{document}